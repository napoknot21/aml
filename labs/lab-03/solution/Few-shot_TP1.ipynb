{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Few-shot - Practical session</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this practical session, you will perform few-shot classification on the MiniImagenet dataset. Here we only focus on the classification aspect of the problem, and not on the training aspect. For this reaon, features are directly provided, so you don't need to train neural networks.\n",
    "\n",
    "Below, you will first find a bunch of pre-written codes, i.e., imports, constants and a few basic functions. Quickly read the constant and function headers to know what you already have access to. Functions to complete will be provided later in this document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Given codes</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Imports</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from IPython.display import display, HTML\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rc(\"font\", size=16)\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Constants</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--features_dir\",\n",
    "                        help=\"Directory containing the features\",\n",
    "                        type=str,\n",
    "                        default=\"./data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--backbone\",\n",
    "                        help=\"Chosen backbone used to generate the features\",\n",
    "                        type=int,\n",
    "                        choices=[1, 2, 3],\n",
    "                        default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--train_val_test_split\",\n",
    "                        help=\"Dimensions of the sets in feature files\",\n",
    "                        type=tuple,\n",
    "                        default=(64, 16, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--nb_ways\",\n",
    "                        help=\"Number of ways for few-shot\",\n",
    "                        type=int,\n",
    "                        default=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--nb_shots\",\n",
    "                        help=\"Number of shots for few-shot\",\n",
    "                        type=int,\n",
    "                        default=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--nb_queries\",\n",
    "                        help=\"Number of queries for few-shot\",\n",
    "                        type=int,\n",
    "                        default=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--nb_runs\",\n",
    "                        help=\"Number of runs to perform\",\n",
    "                        type=int,\n",
    "                        default=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = parser.add_argument(\"--random_seed\",\n",
    "                        help=\"Random seed to initialize the runs\",\n",
    "                        type=int,\n",
    "                        default=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "try :\n",
    "    get_ipython()\n",
    "    ARGS = parser.parse_args(args=[])\n",
    "except :\n",
    "    ARGS = parser.parse_args()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Cuda</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Functions</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy (ground_truth, prediction) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Returns accuracy of a prediction.\n",
    "        In:\n",
    "            * ground_truth: Expected labels.\n",
    "            * prediction: Predicted labels.\n",
    "        Out:\n",
    "            * accuracy: Percentage of correct predictions.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = ((prediction == ground_truth).float().sum() / len(prediction)).item()\n",
    "    \n",
    "    # Done\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_stats (all_accuracies) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Returns the mean and 95% confidence intervals for a list of results.\n",
    "        In:\n",
    "            * all_accuracies: List of accuracies to use.\n",
    "        Out:\n",
    "            * mean_accuracy: Average accuracy.\n",
    "            * confidence_95: 95% confidence interval.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Compute stats\n",
    "    mean_accuracy = np.mean(all_accuracies)\n",
    "    confidence_95 = 1.96 * np.std(all_accuracies) / np.sqrt(len(all_accuracies))\n",
    "    \n",
    "    # Done\n",
    "    return mean_accuracy, confidence_95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_few_shot_data (data, counts_per_class, nb_ways, nb_shots, nb_queries, fixed_ways=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Generates shots and queries from data tensor (label, data, feature).\n",
    "        In:\n",
    "            * data: Data from which to get random samples.\n",
    "            * counts_per_class: Number of data available per class of the dataset.\n",
    "            * nb_ways: Number of ways.\n",
    "            * nb_shots: Number of shots.\n",
    "            * nb_queries: Number of queries.\n",
    "            * fixed_ways: Allows to randomly draw shots for the chosen fixed ways.\n",
    "        Out:\n",
    "            * ways: Ways used.\n",
    "            * x_shots: Labeled data.\n",
    "            * ix_shots: Indices of labeled data.\n",
    "            * i_shots: Associated labels.\n",
    "            * x_queries: Unlabeled data.\n",
    "            * ix_queries: Indices of unlabeled data.\n",
    "            * i_queries: Associated labels to predict.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Choose ways\n",
    "    if fixed_ways is not None :\n",
    "        ways = fixed_ways\n",
    "    else :\n",
    "        ways = np.random.choice(data.shape[0], nb_ways, False)\n",
    "    \n",
    "    # Get random shots/queries indices\n",
    "    y_shots = [way for way in ways for _ in range(nb_shots)]\n",
    "    y_queries = [way for way in ways for _ in range(nb_queries)]\n",
    "    ix_shots = []\n",
    "    ix_queries = []\n",
    "    for way in ways :\n",
    "        shots_queries = np.random.choice(counts_per_class[way], nb_shots + nb_queries, False).tolist()\n",
    "        ix_shots += shots_queries[:nb_shots]\n",
    "        ix_queries += shots_queries[nb_shots:]\n",
    "    \n",
    "    # Get actual data in addition to the indices\n",
    "    x_shots = torch.stack([data[y_shots[i], ix_shots[i], :] for i in range(len(ix_shots))])\n",
    "    x_queries = torch.stack([data[y_queries[i], ix_queries[i], :] for i in range(len(ix_queries))])\n",
    "    \n",
    "    # Additional type conversions\n",
    "    ways = torch.tensor(ways)\n",
    "    ix_shots = torch.tensor(ix_shots)\n",
    "    y_shots = torch.tensor(y_shots)\n",
    "    ix_queries = torch.tensor(ix_queries)\n",
    "    y_queries = torch.tensor(y_queries)\n",
    "    \n",
    "    # Done\n",
    "    return ways, x_shots, ix_shots, y_shots, x_queries, ix_queries, y_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix (matrix, rows_labels=\"\", cols_labels=\"\", rows_title=\"\", cols_title=\"\", title=\"\", colorbar=False, round_values=None, file_name=None) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Plots a matrix.\n",
    "        --\n",
    "        In:\n",
    "            * matrix: Matrix to plot.\n",
    "            * rows_labels: Labels associated with the rows.\n",
    "            * cols_labels: Labels associated with the columns.\n",
    "            * title: Figure title.\n",
    "            * colorbar: Set to True to plot a colorbar.\n",
    "            * round_values: Set to >= 0 to plot values in matrix cells.\n",
    "            * file_name: Where to save the results.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Plot matrix\n",
    "    dimensions = (20, 20 * matrix.shape[0] / matrix.shape[1]) if matrix.shape[0] < matrix.shape[1] else (20 * matrix.shape[1] / matrix.shape[0], 20)\n",
    "    figure, axis = plt.subplots(figsize=dimensions)\n",
    "    cax = axis.matshow(matrix)\n",
    "    \n",
    "    # Add colorbar\n",
    "    if colorbar :\n",
    "        figure.colorbar(cax)\n",
    "    \n",
    "    # Add values\n",
    "    if round_values is not None :\n",
    "        color_change_threshold = 0.5 * (np.max(matrix) + np.min(matrix))\n",
    "        for i in range(matrix.shape[0]) :\n",
    "            for j in range(matrix.shape[1]) :\n",
    "                value = round(matrix[i, j], round_values)\n",
    "                if value == int(value) :\n",
    "                    value = int(value)\n",
    "                color = \"black\" if matrix[i, j] > color_change_threshold else \"white\"\n",
    "                axis.text(j, i, str(value), va=\"center\", ha=\"center\", color=color)\n",
    "    \n",
    "    # Plot\n",
    "    plt.title(title)\n",
    "    plt.yticks(range(matrix.shape[0]))\n",
    "    plt.ylabel(rows_title)\n",
    "    plt.gca().set_yticklabels(rows_labels)\n",
    "    plt.xticks(range(matrix.shape[1]))\n",
    "    plt.xlabel(cols_title)\n",
    "    plt.gca().set_xticklabels(cols_labels)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Save\n",
    "    if file_name is not None :\n",
    "        create_directory_for(file_name)\n",
    "        figure.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_points (xs, ys, legends=[], styles=[], lines=[], xlabel=\"\", ylabel=\"\", title=\"\", file_name=None) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Plots multiple points.\n",
    "        --\n",
    "        In:\n",
    "            * xs: X coordinates.\n",
    "            * ys: Y coordinates.\n",
    "            * legends: Legends to associate with the sets of points.\n",
    "            * styles: Styles of the set of points.\n",
    "            * lines: Custom lines to add as (x0, y0, x1, y1, style) tuples.\n",
    "            * xlabel: X axis label.\n",
    "            * ylabel: Y axis label.\n",
    "            * title: Figure title.\n",
    "            * file_name: Where to save the results.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Plot\n",
    "    figure = plt.figure(figsize=(20, 10), constrained_layout=True)\n",
    "    for i in range(len(ys)) :\n",
    "        actual_legend = \"\" if len(legends) == 0 else legends[i]\n",
    "        actual_styles = None if len(styles) == 0 else styles[i]\n",
    "        plt.scatter(xs[i], ys[i], c=actual_styles, label=actual_legend)\n",
    "    for line in lines :\n",
    "        plt.plot([line[0], line[2]], [line[1], line[3]], line[4])\n",
    "    plt.xlabel(xlabel)\n",
    "    plt.ylabel(ylabel)\n",
    "    if len(legends) > 0 :\n",
    "        plt.legend()\n",
    "    plt.title(title)\n",
    "    figure.gca().spines[\"right\"].set_visible(False)\n",
    "    figure.gca().spines[\"top\"].set_visible(False)\n",
    "    plt.show()\n",
    "    \n",
    "    # Save\n",
    "    if file_name is not None :\n",
    "        create_directory_for(file_name)\n",
    "        figure.savefig(file_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed (seed) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Fixes all possible seeds.\n",
    "        In:\n",
    "            * seed: Seed value.\n",
    "        Out:\n",
    "            * None.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Compute a random value based on the global seed to act as starting point\n",
    "    # We remove the number of runs since we use random seeds to always generate the same runs\n",
    "    np.random.seed(ARGS.random_seed)\n",
    "    init = np.random.randint(2**32 - 1 - ARGS.nb_runs)\n",
    "    \n",
    "    # Random libs seeds\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.manual_seed(init + seed)\n",
    "    torch.cuda.manual_seed_all(init + seed)\n",
    "    np.random.seed(init + seed)\n",
    "    random.seed(init + seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Few-shot classification</center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this part is to maximize the average performance (over 10k random runs) of a few-shot classifier.\n",
    "\n",
    "First, let's load the provided features. These features are tensors of dimension (X, Y, Z), where X is the number of classes, Y is the number of data points per class, and Z is the feature size. We have provided you 3 feature tensors, that have been generated using 3 different backbones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load features\n",
    "features = torch.load(ARGS.features_dir + os.path.sep + \"minifeatures\" + str(ARGS.backbone) + \".pt11\", map_location=DEVICE)\n",
    "train_set = features[:ARGS.train_val_test_split[0]]\n",
    "val_set = features[ARGS.train_val_test_split[0]:ARGS.train_val_test_split[0]+ARGS.train_val_test_split[1]]\n",
    "test_set = features[ARGS.train_val_test_split[0]+ARGS.train_val_test_split[1]:]\n",
    "\n",
    "# With this dataset, we have the same number of data points per class\n",
    "test_set_counts = [test_set.shape[1]] * test_set.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u><b>TODO:</b></u> Preprocess the features to improve performance (you can skip this first and come back to fill this cell later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess (vectors, train_vectors, operations=\"\") :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Preprocesses vectors as indicated.\n",
    "        In:\n",
    "            * vectors: Vectors to preprocess.\n",
    "            * train_vectors: Reference vectors for preprocessing.\n",
    "            * operations: String describing the preprocessing steps to perform (e.g., 'CH', 'HCH').\n",
    "        Out:\n",
    "            * preprocessed_vectors: Preprocessed vectors.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # Iterate over preprocessing string\n",
    "    preprocessed_vectors = vectors.clone()\n",
    "    preprocessed_train = train_vectors.clone()\n",
    "    for operation in operations :\n",
    "        \n",
    "        # Project on hypersphere\n",
    "        if operation == 'H' :\n",
    "            pass # TODO\n",
    "        \n",
    "        # Center vectors around train vectors mean\n",
    "        elif operation == 'C' :\n",
    "            pass # TODO\n",
    "            \n",
    "        # Error\n",
    "        else :\n",
    "            raise Exception(\"Invalid operation chosen: %s\" % operation)\n",
    "        \n",
    "    # Done\n",
    "    return preprocessed_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "test_set = preprocess(test_set, train_set, \"CH\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below is a generic function that will perform few-shot classification, averaged over multiple runs. In this code, we also compute the confusion matrix between test set classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_runs (test_set, test_set_counts, setting=\"inductive\", fixed_ways=None, compute_confusion_matrix=False) :\n",
    "    \n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Performs projections and classifications.\n",
    "        In:\n",
    "            * test_set: Set from which to get the shots/queries.\n",
    "            * test_set_counts: Number of data available per class of the test set.\n",
    "            * setting: Inductive or transductive.\n",
    "            * fixed_ways: Allows to randomly draw shots for the chosen fixed ways.\n",
    "            * compute_confusion_matrix: Indicates if we compute the confusion matrix for all runs.\n",
    "        Out :\n",
    "            * all_accuracies: Accuracies obtained for all runs.\n",
    "            * global_confusion_matrix: Confusion matrix obtained across all runs.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # Generate runs\n",
    "    all_accuracies = []\n",
    "    global_confusion_matrix = np.zeros((test_set.shape[0], test_set.shape[0])) if compute_confusion_matrix else None\n",
    "    for run in range(ARGS.nb_runs) :\n",
    "\n",
    "        # Generate problem\n",
    "        set_seed(run)\n",
    "        ways, x_shots, ix_shots, y_shots, x_queries, ix_queries, y_queries = generate_few_shot_data(test_set, test_set_counts, ARGS.nb_ways, ARGS.nb_shots, ARGS.nb_queries, fixed_ways)\n",
    "\n",
    "        # Solve the problem\n",
    "        if setting == \"inductive\" :\n",
    "            estimated_y_queries = nearest_class_mean(ways, x_shots, y_shots, x_queries)\n",
    "        elif setting == \"transductive\" :\n",
    "            estimated_y_queries = soft_k_means(ways, x_shots, y_shots, x_queries)\n",
    "        else :\n",
    "            raise Exception(\"Invalid setting chosen: %s\" % ARGS.setting)\n",
    "        \n",
    "        # Verify accuracy\n",
    "        accuracy = compute_accuracy(y_queries, estimated_y_queries)\n",
    "        all_accuracies.append(accuracy)\n",
    "    \n",
    "        # Compute confusion matrix\n",
    "        if compute_confusion_matrix or run in runs_to_plot :\n",
    "            confusion_matrix = sklearn.metrics.confusion_matrix(y_queries, estimated_y_queries, labels=ways)\n",
    "            if compute_confusion_matrix :\n",
    "                for i in range(confusion_matrix.shape[0]) :\n",
    "                    for j in range(confusion_matrix.shape[1]) :\n",
    "                        global_confusion_matrix[ways[i], ways[j]] += confusion_matrix[i, j]\n",
    "        \n",
    "    # Done\n",
    "    return all_accuracies, global_confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us work in inductive setting first. For recall, in this setting, queries cannot be used to improve the classification. The simplest classifier that can be used is a nearest mean classifier (NCM). You can find a description of that classifier here for instance: https://arxiv.org/abs/2201.09699.\n",
    "\n",
    "<u><b>TODO:</b></u> Please fill the function below to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_class_mean (ways, x_shots, y_shots, x_queries) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Nearest class mean algorithm.\n",
    "        In:\n",
    "            * ways: Possible labels.\n",
    "            * x_shots: Labeled data.\n",
    "            * y_shots: Labels.\n",
    "            * x_queries: Unlabeled data.\n",
    "        Out:\n",
    "            * y_queries: Predicted labels for unlabeled data.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "    \n",
    "    # TODO\n",
    "    \n",
    "    # Done\n",
    "    return y_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this classifier to predict labels for queries in multiple runs. For `ARGS.random_seed = 0`, we obtain the following performance:\n",
    "* Backbone #1: 63.3876% +/- 0.196481\n",
    "* Backbone #2: 67.814800 +/- 0.194246\n",
    "* Backbone #3: 68.277733% +/- 0.196579\n",
    "\n",
    "<u><b>TODO:</b></u> Experiment various preprocessing methods, backbones, etc. in order to get the best performance you can over 10,000 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify\n",
    "all_accuracies, confusion_matrix = make_runs(test_set, test_set_counts, \"inductive\", compute_confusion_matrix=True)\n",
    "mean_accuracy, confidence_95 = compute_accuracy_stats(all_accuracies)\n",
    "plot_matrix(confusion_matrix,\n",
    "            rows_labels=list(range(test_set.shape[0])),\n",
    "            cols_labels=list(range(test_set.shape[0])),\n",
    "            rows_title=\"Actual class\",\n",
    "            cols_title=\"Predicted class\",\n",
    "            title=\"%f%% +/- %f\\nConfusion matrix:\" % (100 * mean_accuracy, 100 * confidence_95),\n",
    "            round_values=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also work in the transductive setting, where we can exploit the queries during the classificationt task. A possible classifier is the soft K-means algorithm. You can find a description of that classifier here for instance: https://arxiv.org/abs/2201.09699.\n",
    "\n",
    "<u><b>TODO (optional, advanced):</b></u> Fill the function below to implement it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soft_k_means (ways, x_shots, y_shots, x_queries, temperature=5) :\n",
    "\n",
    "    ###########################################################################################################\n",
    "    \"\"\"\n",
    "        Soft K-means algorithm.\n",
    "        In:\n",
    "            * ways: Possible labels.\n",
    "            * x_shots: Labeled data.\n",
    "            * y_shots: Labels.\n",
    "            * x_queries: Unlabeled data.\n",
    "        Out:\n",
    "            * y_queries: Predicted labels for unlabeled data.\n",
    "    \"\"\"\n",
    "    ###########################################################################################################\n",
    "\n",
    "    # TODO\n",
    "    \n",
    "    # Done\n",
    "    return y_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use this classifier to predict labels for queries in multiple runs. For `ARGS.random_seed = 0`, we obtain the following performance:\n",
    "* Backbone #1: 74.890133% +/- 0.210404\n",
    "* Backbone #2: 74.228% +/- 0.209706\n",
    "* Backbone #3: 74.939467% +/- 0.210941\n",
    "\n",
    "<u><b>TODO:</b></u> Experiment various preprocessing methods, backbones, etc. in order to get the best performance you can over 10,000 runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify\n",
    "all_accuracies, confusion_matrix = make_runs(test_set, test_set_counts, \"transductive\", compute_confusion_matrix=True)\n",
    "mean_accuracy, confidence_95 = compute_accuracy_stats(all_accuracies)\n",
    "plot_matrix(confusion_matrix,\n",
    "            rows_labels=list(range(test_set.shape[0])),\n",
    "            cols_labels=list(range(test_set.shape[0])),\n",
    "            rows_title=\"Actual class\",\n",
    "            cols_title=\"Predicted class\",\n",
    "            title=\"%f%% +/- %f\\nConfusion matrix:\" % (100 * mean_accuracy, 100 * confidence_95),\n",
    "            round_values=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
